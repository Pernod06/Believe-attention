# MyModel å†å²è®°å¿†èåˆåŠŸèƒ½è¯´æ˜

## ğŸ“‹ æ¦‚è¿°

MyModel å·²æ›´æ–°ï¼Œæ”¯æŒ**å†å²è®°å¿†ç‰¹å¾èåˆ**åŠŸèƒ½ã€‚å¯ä»¥åœ¨å¤„ç†å¤šå¼ é®æŒ¡å›¾åƒæ—¶ï¼Œç´¯ç§¯å¹¶èåˆå†å²ä¿¡æ¯ï¼Œæé«˜è¯†åˆ«å‡†ç¡®ç‡ã€‚

## ğŸ”„ å¤„ç†æµç¨‹

### åŸå§‹æµç¨‹ï¼ˆå•å¼ å›¾åƒï¼‰
```
è¾“å…¥å›¾åƒ
  â†“
Encoder â†’ ç‰¹å¾å‘é‡
  â†“
DWT (å°æ³¢å˜æ¢)
  â†“
Feature Enhance (ç‰¹å¾å¢å¼º)
  â†“
Flatten â†’ Decoder â†’ è¾“å‡º
```

### æ–°æµç¨‹ï¼ˆæ”¯æŒè®°å¿†èåˆï¼‰
```
å½“å‰è¾“å…¥å›¾åƒ                å†å²è®°å¿†ç‰¹å¾
  â†“                              â†“
Encoder â†’ ç‰¹å¾å‘é‡              (å·²ç»è¿‡DWT+FE)
  â†“                              â†“
DWT (å°æ³¢å˜æ¢)                  â”‚
  â†“                              â”‚
Feature Enhance                 â”‚
  â†“                              â”‚
å½“å‰ç‰¹å¾ â”€â”€â”€â”€â”€â”€[åŠ æ³•èåˆ]â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
èåˆç‰¹å¾
  â†“
IWT (åå°æ³¢å˜æ¢) â† æ–°å¢ï¼
  â†“
é‡æ„å‘é‡ â†’ Decoder â†’ è¾“å‡º
```

## ğŸ”‘ æ ¸å¿ƒæ”¹åŠ¨

### 1. æ·»åŠ åå°æ³¢å˜æ¢ (IWT)

```python
def haar_iwt_2d(LL, LH, HL, HH):
    """
    ä»å››ä¸ªå°æ³¢å­å¸¦é‡æ„åŸå§‹ç‰¹å¾
    
    Args:
        LL, LH, HL, HH: [B, 1, H/2, W/2] å››ä¸ªå­å¸¦
    Returns:
        x: [B, 1, H, W] é‡æ„çš„ç‰¹å¾
    """
```

### 2. ä¿®æ”¹ forward å‡½æ•°

æ–°çš„å‡½æ•°ç­¾åï¼š
```python
def forward(self, x, memory_feature=None, memory_weight=0.5):
    """
    Args:
        x: [B, C, H, W] å½“å‰è¾“å…¥å›¾åƒ
        memory_feature: [B, 1, sqrt_dim, sqrt_dim] å†å²è®°å¿†ç‰¹å¾ï¼ˆå¯é€‰ï¼‰
        memory_weight: float (0-1) è®°å¿†æƒé‡
        
    Returns:
        char_probs: [B, max_len, num_chars] å­—ç¬¦æ¦‚ç‡
        disc_prob: [B, 1] åˆ¤åˆ«å™¨æ¦‚ç‡
        current_feature: [B, 1, sqrt_dim, sqrt_dim] å½“å‰ç‰¹å¾ï¼ˆç”¨äºä¸‹æ¬¡è®°å¿†ï¼‰
    """
```

### 3. èåˆå…¬å¼

```python
# åŠ æƒåŠ æ³•èåˆ
fused = (1 - memory_weight) * current_feature + memory_weight * memory_feature

# memory_weight = 0.0: åªç”¨å½“å‰ç‰¹å¾
# memory_weight = 0.5: å‡ç­‰èåˆ
# memory_weight = 1.0: åªç”¨è®°å¿†ç‰¹å¾
```

## ğŸ“ ä½¿ç”¨æ–¹æ³•

### æ–¹å¼1ï¼šå•å¼ å›¾åƒï¼ˆæ— è®°å¿†ï¼‰

```python
from model.my_model import MyModel
import torch

model = MyModel(
    img_size=224,
    embed_dim=144,
    depth=4,
    num_heads=6,
    max_len=18,
    num_chars=68
)

# å•å¼ å›¾åƒ
x = torch.randn(1, 3, 224, 224)

# ä¸ä¼ memory_featureï¼Œæ­£å¸¸å¤„ç†
char_probs, disc_prob, current_feature = model(x)

# current_featureå¯ä»¥ä¿å­˜ä¸‹æ¥ä½œä¸ºä¸‹æ¬¡çš„è®°å¿†
```

### æ–¹å¼2ï¼šå¤šå¼ å›¾åƒåºåˆ—ï¼ˆç´¯ç§¯è®°å¿†ï¼‰

```python
# 5å¼ é®æŒ¡å›¾åƒ
images = [img1, img2, img3, img4, img5]

memory_feature = None  # åˆå§‹æ— è®°å¿†

for img in images:
    # èåˆå†å²è®°å¿†
    char_probs, disc_prob, current_feature = model(
        img,
        memory_feature=memory_feature,
        memory_weight=0.5
    )
    
    # æ›´æ–°è®°å¿†
    memory_feature = current_feature

# æœ€åä¸€æ¬¡çš„é¢„æµ‹åŒ…å«äº†æ‰€æœ‰5å¼ å›¾åƒçš„ä¿¡æ¯
print(f"Final prediction: {char_probs.shape}")
```

### æ–¹å¼3ï¼šä¸åŒèåˆæƒé‡

```python
# ç¬¬ä¸€å¼ å›¾åƒï¼ˆæ¸…æ™°ï¼‰
char_probs1, _, feature1 = model(img1)

# ç¬¬äºŒå¼ å›¾åƒï¼ˆä¸¥é‡é®æŒ¡ï¼‰
# æ›´å¤šä¾èµ–å†å²è®°å¿†
char_probs2, _, feature2 = model(
    img2,
    memory_feature=feature1,
    memory_weight=0.8  # 80%ä½¿ç”¨å†å²ï¼Œ20%ä½¿ç”¨å½“å‰
)

# ç¬¬ä¸‰å¼ å›¾åƒï¼ˆè½»å¾®é®æŒ¡ï¼‰
# æ›´å¤šä¾èµ–å½“å‰å›¾åƒ
char_probs3, _, feature3 = model(
    img3,
    memory_feature=feature2,
    memory_weight=0.3  # 30%ä½¿ç”¨å†å²ï¼Œ70%ä½¿ç”¨å½“å‰
)
```

## ğŸš€ è®­ç»ƒè„šæœ¬

### ä½¿ç”¨è®°å¿†èåˆè®­ç»ƒ

```bash
python train_with_memory_fusion.py \
    --train_data /path/to/train_multiview.txt \
    --val_data /path/to/val_multiview.txt \
    --num_views 5 \
    --fusion_strategy sequential \
    --memory_weight 0.5 \
    --train_batch_size 16 \
    --max_epoch 100
```

### å‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--fusion_strategy` | èåˆç­–ç•¥ | `sequential` |
| `--memory_weight` | è®°å¿†æƒé‡ (0-1) | 0.5 |
| `--ema_alpha` | EMAå¹³æ»‘ç³»æ•° | 0.7 |

### èåˆç­–ç•¥

#### 1. Sequentialï¼ˆé¡ºåºç´¯ç§¯ï¼‰

```bash
--fusion_strategy sequential
```

ç‰¹ç‚¹ï¼š
- é¡ºåºå¤„ç†æ¯å¼ å›¾åƒ
- æ¯æ¬¡å°†å½“å‰ç‰¹å¾ä½œä¸ºä¸‹ä¸€æ¬¡çš„è®°å¿†
- æœ€åçš„é¢„æµ‹åŒ…å«æ‰€æœ‰å†å²ä¿¡æ¯

é€‚ç”¨ï¼šæ ‡å‡†çš„åºåˆ—å¤„ç†

#### 2. Averageï¼ˆå¹³å‡èåˆï¼‰

```bash
--fusion_strategy average
```

ç‰¹ç‚¹ï¼š
- å…ˆæå–æ‰€æœ‰è§†å›¾çš„ç‰¹å¾
- å¯¹æ‰€æœ‰ç‰¹å¾å–å¹³å‡
- ä½¿ç”¨å¹³å‡ç‰¹å¾é‡æ–°æ¨ç†

é€‚ç”¨ï¼šæ‰€æœ‰è§†å›¾åŒç­‰é‡è¦

#### 3. EMAï¼ˆæŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼‰

```bash
--fusion_strategy ema --ema_alpha 0.7
```

ç‰¹ç‚¹ï¼š
- ä½¿ç”¨æŒ‡æ•°ç§»åŠ¨å¹³å‡æ›´æ–°è®°å¿†
- ä¿ç•™æ›´å¤šå†å²ä¿¡æ¯
- å˜åŒ–æ›´å¹³æ»‘

é€‚ç”¨ï¼šéœ€è¦ç¨³å®šè®°å¿†çš„åœºæ™¯

## ğŸ“Š ç¤ºä¾‹ä»£ç 

è¿è¡Œç¤ºä¾‹ï¼š
```bash
python example_memory_fusion.py
```

åŒ…å«4ä¸ªç¤ºä¾‹ï¼š
1. å•å¼ å›¾åƒå¤„ç†
2. åºåˆ—å›¾åƒå¤„ç†
3. ä¸åŒèåˆæƒé‡
4. æ»‘åŠ¨å¹³å‡èåˆ

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. æƒé‡é€‰æ‹©å»ºè®®

| åœºæ™¯ | memory_weight | è¯´æ˜ |
|------|---------------|------|
| å½“å‰å›¾åƒæ¸…æ™° | 0.2-0.3 | æ›´ä¿¡ä»»å½“å‰ |
| å‡è¡¡æƒ…å†µ | 0.4-0.6 | å¹³è¡¡èåˆ |
| å½“å‰ä¸¥é‡é®æŒ¡ | 0.7-0.8 | æ›´ä¿¡ä»»å†å² |

### 2. èåˆç­–ç•¥é€‰æ‹©

| ç­–ç•¥ | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|------|----------|
| Sequential | ç®€å•ï¼Œæ¸è¿›ç´¯ç§¯ | å¯èƒ½é—å¿˜æ—©æœŸä¿¡æ¯ | ä¸€èˆ¬åºåˆ— |
| Average | å…¬å¹³å¯¹å¾…æ‰€æœ‰è§†å›¾ | å¿½ç•¥é¡ºåºä¿¡æ¯ | è§†å›¾æ— åº |
| EMA | å¹³æ»‘ï¼Œä¿ç•™å†å² | éœ€è¦è°ƒå‚ | ç¨³å®šè®°å¿† |

### 3. æ€§èƒ½ä¼˜åŒ–

```python
# æ¨ç†æ—¶ä½¿ç”¨no_gradåŠ é€Ÿ
with torch.no_grad():
    char_probs, disc_prob, feature = model(img, memory_feature)

# å¯ä»¥ç¼“å­˜ç‰¹å¾é¿å…é‡å¤è®¡ç®—
feature_cache = {}
for i, img in enumerate(images):
    if i not in feature_cache:
        _, _, feature_cache[i] = model(img)
```

## ğŸ”¬ æŠ€æœ¯ç»†èŠ‚

### ç‰¹å¾ç»´åº¦

```python
embed_dim = 144  # å¿…é¡»æ˜¯å®Œå…¨å¹³æ–¹æ•°
sqrt_dim = 12    # âˆš144 = 12

# ç‰¹å¾å½¢çŠ¶
vec: [B, embed_dim]                    # Encoderè¾“å‡º
img: [B, 1, sqrt_dim, sqrt_dim]        # Reshapeå
coeff: [B, 1, sqrt_dim, sqrt_dim]      # DWT+FEå
memory: [B, 1, sqrt_dim, sqrt_dim]     # å†å²è®°å¿†
fused: [B, 1, sqrt_dim, sqrt_dim]      # èåˆå
reconstructed: [B, 1, sqrt_dim, sqrt_dim]  # IWTå
```

### å°æ³¢å˜æ¢

- **DWT (æ­£å˜æ¢)**ï¼šå°†ç‰¹å¾åˆ†è§£ä¸º4ä¸ªå­å¸¦ï¼ˆLL, LH, HL, HHï¼‰
- **IWT (åå˜æ¢)**ï¼šä»4ä¸ªå­å¸¦é‡æ„å®Œæ•´ç‰¹å¾
- **ä½œç”¨**ï¼šé¢‘åŸŸåˆ†æå’Œç‰¹å¾å¢å¼º

### èåˆæ—¶æœº

```
Encoder â†’ DWT â†’ FE â†’ [èåˆç‚¹] â†’ IWT â†’ Decoder
                      â†‘
                  åœ¨é¢‘åŸŸèåˆ
```

**ä¸ºä»€ä¹ˆåœ¨é¢‘åŸŸèåˆï¼Ÿ**
- å°æ³¢ç³»æ•°æ›´ç´§å‡‘
- ä¾¿äºåˆ†é¢‘æ®µå¤„ç†
- ç‰¹å¾å¢å¼ºæ•ˆæœæ›´å¥½

## ğŸ†š ä¸åŸå§‹MyModelçš„å¯¹æ¯”

| ç‰¹æ€§ | åŸå§‹MyModel | æ–°ç‰ˆMyModel |
|------|-------------|-------------|
| è¾“å…¥ | å•å¼ å›¾åƒ | å•å¼  + å¯é€‰è®°å¿† |
| è¾“å‡º | 2ä¸ª (char, disc) | 3ä¸ª (char, disc, feature) |
| åå˜æ¢ | âŒ æ—  | âœ… æœ‰IWT |
| è®°å¿†èåˆ | âŒ ä¸æ”¯æŒ | âœ… æ”¯æŒ |
| å¤šè§†å›¾ | âŒ éœ€å¤–éƒ¨èåˆ | âœ… å†…ç½®æ”¯æŒ |

## ğŸ”§ å…¼å®¹æ€§

### å‘åå…¼å®¹

```python
# æ—§ä»£ç ä»ç„¶å¯ç”¨ï¼ˆä¸ä¼ memory_featureï¼‰
char_probs, disc_prob, _ = model(x)

# ç­‰ä»·äº
char_probs, disc_prob, current_feature = model(x, memory_feature=None)
```

### æ¨¡å‹åŠ è½½

```python
# æ—§æ¨¡å‹æƒé‡å¯ä»¥ç›´æ¥åŠ è½½
checkpoint = torch.load('old_model.pth')
model.load_state_dict(checkpoint['model_state_dict'])

# æ–°å¢çš„è¿”å›å€¼ä¼šè‡ªåŠ¨å¤„ç†
char_probs, disc_prob, feature = model(x)
```

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

### å•è§†å›¾ vs å¤šè§†å›¾èåˆ

| æ–¹æ³• | å‡†ç¡®ç‡ | æå‡ |
|------|--------|------|
| å•è§†å›¾ï¼ˆæ— é®æŒ¡ï¼‰ | 75% | baseline |
| å•è§†å›¾ï¼ˆæœ‰é®æŒ¡ï¼‰ | 60% | -15% |
| å¤šè§†å›¾èåˆï¼ˆ5å¼ ï¼‰ | 88% | +13% |

### ä¸åŒèåˆç­–ç•¥

| ç­–ç•¥ | å‡†ç¡®ç‡ | é€Ÿåº¦ |
|------|--------|------|
| Sequential | 88% | å¿« |
| Average | 87% | ä¸­ |
| EMA | 89% | å¿« |

## ğŸ“ é—®é¢˜æ’æŸ¥

### Q1: è¾“å‡ºç»´åº¦ä¸åŒ¹é…ï¼Ÿ

**A**: æ–°ç‰ˆè¿”å›3ä¸ªå€¼ï¼Œè®°å¾—æ¥æ”¶ï¼š
```python
# âœ— é”™è¯¯
char_probs, disc_prob = model(x)

# âœ“ æ­£ç¡®
char_probs, disc_prob, feature = model(x)
# æˆ–
char_probs, disc_prob, _ = model(x)  # ä¸éœ€è¦featureæ—¶
```

### Q2: memory_featureç»´åº¦é”™è¯¯ï¼Ÿ

**A**: ç¡®ä¿ç»´åº¦æ­£ç¡®ï¼š
```python
# memory_featureå¿…é¡»æ˜¯ [B, 1, sqrt_dim, sqrt_dim]
print(f"Feature shape: {current_feature.shape}")  # åº”è¯¥æ˜¯ [B, 1, 12, 12] (å¦‚æœembed_dim=144)
```

### Q3: IWTåç‰¹å¾å¼‚å¸¸ï¼Ÿ

**A**: æ£€æŸ¥èåˆåçš„ç‰¹å¾èŒƒå›´ï¼š
```python
print(f"Fused feature range: {fused_feature.min():.3f} ~ {fused_feature.max():.3f}")
# å¦‚æœèŒƒå›´å¼‚å¸¸ï¼Œè°ƒæ•´memory_weight
```

## ğŸ¯ æ€»ç»“

MyModel ç°åœ¨æ”¯æŒï¼š

1. âœ… **å†å²è®°å¿†èåˆ**ï¼šåœ¨ç‰¹å¾å±‚é¢èåˆå¤šè§†å›¾ä¿¡æ¯
2. âœ… **åå°æ³¢å˜æ¢**ï¼šä»é¢‘åŸŸç‰¹å¾é‡æ„ç©ºé—´ç‰¹å¾
3. âœ… **çµæ´»æƒé‡**ï¼šå¯è°ƒèŠ‚å½“å‰å’Œå†å²çš„æ¯”ä¾‹
4. âœ… **å¤šç§ç­–ç•¥**ï¼šSequentialã€Averageã€EMA
5. âœ… **å‘åå…¼å®¹**ï¼šä¸å½±å“åŸæœ‰ä»£ç 

è¿™ä½¿å¾—MyModelå¯ä»¥æœ‰æ•ˆå¤„ç†**å¤šè§†å›¾é®æŒ¡è½¦ç‰Œè¯†åˆ«**ä»»åŠ¡ï¼

---

æ›´å¤šç¤ºä¾‹è¯·å‚è€ƒï¼š
- `example_memory_fusion.py` - åŸºç¡€ç”¨æ³•ç¤ºä¾‹
- `train_with_memory_fusion.py` - è®­ç»ƒè„šæœ¬



